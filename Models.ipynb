{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "import pandas as pd\n",
    "\n",
    "# train_test_split & cross validation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# creating piplines\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# creating models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('run_pass_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for the train_test_split\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df.Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2020, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a pipeline to do all of our preprocessing for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = make_column_transformer((OneHotEncoder(), make_column_selector(dtype_include=object)),\n",
    "                                       (StandardScaler(), make_column_selector(dtype_include=np.number),\n",
    "                                        SMOTE()))\n",
    "\n",
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform our preprocessing pipeline to our training data\n",
    "preprocessing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next thing we'll do is make separate pipelines for each model we want to test\n",
    "# each of these pipelines will contain our preprocessing pipeline\n",
    "\n",
    "dt_pipeline = make_pipeline(preprocessing, DecisionTreeClassifier(random_state=2021))\n",
    "rf_pipeline = make_pipeline(preprocessing, RandomForestClassifier(random_state=2021))\n",
    "lr_pipeline = make_pipeline(preprocessing, LogisticRegression(random_state=2021))\n",
    "et_pipeline = make_pipeline(preprocessing, ExtraTreesClassifier(random_state=2021))\n",
    "kn_pipeline = make_pipeline(preprocessing, KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Param_Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different param_grids for each pipeline\n",
    "\n",
    "dt_param_grid = {\n",
    "    'decisiontreeclassifier__criterion': ['entropy', 'gini'],\n",
    "    'decisiontreeclassifier__splitter': ['best', 'random'],\n",
    "    'decisiontreeclassifier__max_depth': [2, 5, 10],\n",
    "    'decisiontreeclassifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'decisiontreeclassifier__class_weight': ['none', 'balanced']\n",
    "    \n",
    "}\n",
    "\n",
    "rf_param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [100, 1000, 2000],\n",
    "    'randomforestclassifier__max_depth': [2, 5, 10]\n",
    "    \n",
    "}\n",
    "\n",
    "lr_param_grid = {\n",
    "    'logisticregression__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'logisticregression__dual': [True, False],\n",
    "    'logisticregression__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'logisticregression__multi_class': ['auto', 'ovr', 'multinomial'],\n",
    "    'logisticregression__n_jobs': [10, 20, 30],\n",
    "    'logisticregression__C': [0.01, 0.1, 0.5]\n",
    "    \n",
    "}\n",
    "\n",
    "et_param_grid = {\n",
    "    'extratreesclassifier__criterion': ['entropy', 'gini'],\n",
    "    'extratreesclassifier__max_depth': [2, 5, 10],\n",
    "    'extratreesclassifier__n_estimators': [100, 250, 500],\n",
    "    'extratreesclassifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'extratreesclassifier__class_weight': ['none', 'balanced']\n",
    "    \n",
    "}\n",
    "\n",
    "kn_param_grid = {\n",
    "    'kneighborsclassifier__n_neighbors': [5, 10, 20],\n",
    "    'kneighborsclassifier__weights': ['uniform', 'distance'],\n",
    "    'kneighborsclassifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'kneighborsclassifier__leaf_size': [25, 50, 100],\n",
    "    'kneighborsclassifier__p': [1, 2],\n",
    "    'kneighborsclassifier__metric': ['minkowski', 'manhattan']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_lr = GridSearchCV(lr_pipeline, lr_param_grid, n_jobs=-1)\n",
    "\n",
    "search_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can check its best parameters\n",
    "search_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign best model to a variable using best_estimator_\n",
    "best_lr_pipeline = search_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation using the accuracy, precision, recall, and f1 score metric\n",
    "best_lr_cross_val_acc = cross_val_score(best_lr_pipeline, X_train, y_train, scoring='accuracy')\n",
    "best_lr_cross_val_prec = cross_val_score(best_lr_pipeline, X_train, y_train, scoring='precision')\n",
    "best_lr_cross_val_rec = cross_val_score(best_lr_pipeline, X_train, y_train, scoring='recall')\n",
    "best_lr_cross_val_f1 = cross_val_score(best_lr_pipeline, X_train, y_train, scoring='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_dt = GridSearchCV(dt_pipeline, dt_param_grid, n_jobs=-1)\n",
    "\n",
    "search_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can check its best parameters\n",
    "search_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign best model to a variable using best_estimator_\n",
    "best_dt_pipeline = search_dt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation using the accuracy, precision, recall, and f1 score metric\n",
    "best_dt_cross_val_acc = cross_val_score(best_dt_pipeline, X_train, y_train, scoring='accuracy')\n",
    "best_dt_cross_val_prec= cross_val_score(best_dt_pipeline, X_train, y_train, scoring='precision')\n",
    "best_dt_cross_val_rec = cross_val_score(best_dt_pipeline, X_train, y_train, scoring='recall')\n",
    "best_dt_cross_val_f1 = cross_val_score(best_dt_pipeline, X_train, y_train, scoring='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_rf = GridSearchCV(rf_pipeline, rf_param_grid, n_jobs=-1)\n",
    "\n",
    "search_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can check its best parameters\n",
    "search_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign best model to a variable using best_estimator_\n",
    "best_rf_pipeline = search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation using the accuracy, precision, recall, and f1 score metric\n",
    "best_rf_cross_val_acc = cross_val_score(best_rf_pipeline, X_train, y_train, scoring='accuracy')\n",
    "best_rf_cross_val_prec= cross_val_score(best_rf_pipeline, X_train, y_train, scoring='precision')\n",
    "best_rf_cross_val_rec = cross_val_score(best_rf_pipeline, X_train, y_train, scoring='recall')\n",
    "best_rf_cross_val_f1 = cross_val_score(best_rf_pipeline, X_train, y_train, scoring='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_et = GridSearchCV(et_pipeline, et_param_grid, n_jobs=-1)\n",
    "\n",
    "search_et.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can check its best parameters\n",
    "search_et.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign best model to a variable using best_estimator_\n",
    "best_et_pipeline = search_et.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation using the f1 score metric\n",
    "best_et_cross_val = cross_val_score(best_et_pipeline, X_train, y_train, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation using the accuracy, precision, recall, and f1 score metric\n",
    "best_et_cross_val_acc = cross_val_score(best_et_pipeline, X_train, y_train, scoring='accuracy')\n",
    "best_et_cross_val_prec= cross_val_score(best_et_pipeline, X_train, y_train, scoring='precision')\n",
    "best_et_cross_val_rec = cross_val_score(best_et_pipeline, X_train, y_train, scoring='recall')\n",
    "best_et_cross_val_f1 = cross_val_score(best_et_pipeline, X_train, y_train, scoring='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation using the f1 score metric\n",
    "best_kn_cross_val = cross_val_score(best_kn_pipeline, X_train, y_train, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_kn = GridSearchCV(kn_pipeline, kn_param_grid, n_jobs=-1)\n",
    "\n",
    "search_kn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can check its best parameters\n",
    "search_kn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign best model to a variable using best_estimator_\n",
    "best_kn_pipeline = search_kn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation using the accuracy, precision, recall, and f1 score metric\n",
    "best_kn_cross_val_acc = cross_val_score(best_kn_pipeline, X_train, y_train, scoring='accuracy')\n",
    "best_kn_cross_val_prec= cross_val_score(best_kn_pipeline, X_train, y_train, scoring='precision')\n",
    "best_kn_cross_val_rec = cross_val_score(best_kn_pipeline, X_train, y_train, scoring='recall')\n",
    "best_kn_cross_val_f1 = cross_val_score(best_kn_pipeline, X_train, y_train, scoring='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    ">>> df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_f1_scores = {'LogisticRegression': best_lr_cross_val.mean(),\n",
    "                  'DecisionsTree': best_dt_cross_val.mean(),\n",
    "                  'RandomForest': best_rf_cross_val.mean(),\n",
    "                  'ExtraTrees': None,\n",
    "                  'KNeighbors': None}\n",
    "\n",
    "f1_df = pd.DataFrame(data=mean_f1_scores, index=mean_f1_scores[0], columns=mean_f1_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['LogisticRegression', 'DecisionTree', 'RandomForest', \n",
    "              'ExtraTrees', 'KNeighbors'], \n",
    "    'Accuracy': [best_lg_cross_val_acc, best_dt_cross_val_acc, best_rf_cross_val_acc, \n",
    "               best_et_cross_val_acc, best_kn_cross_val_acc], \n",
    "    'Precision': [best_lg_cross_val_prec, best_dt_cross_val_prec, best_rf_cross_val_prec, \n",
    "               best_et_cross_val_prec, best_kn_cross_val_prec], \n",
    "    'Recall': [best_lg_cross_val_rec, best_dt_cross_val_rec, best_rf_cross_val_rec, \n",
    "               best_et_cross_val_rec, best_kn_cross_val_rec],\n",
    "    'F1 Score': [best_lg_cross_val_f1, best_dt_cross_val_f1, best_rf_cross_val_f1, \n",
    "               best_et_cross_val_f1, best_kn_cross_val_f1]}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.sort_values(by='Precision', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.sort_values(by='F1 Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.sort_values(by='Recall', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
